# model name
TheBloke/StableBeluga2-70B-GPTQ

# model hf link
https://huggingface.co/TheBloke/StableBeluga2-70B-GPTQ

# 工夫

## モデルの選定理由
Slackで名前が挙がっており、試してみたところ性能も良かったので採用した。  
初めはlightblue/openorca_stxを使っており、要約タスクではこちらを使用したほうがスコアが高かった。  
(選択タスクはStableBeluga2-70B-GPTQ、要約タスクはopenorca_stxという組み合わせで、その他の工夫も含めてスコア4.5程度)  
しかし、これはopenorca_stxがリーダーボードの要約タスクのデータ(XLSum)のtrain dataでfine-tuningされているためのようであった。  
XLSumは自分で見ると要約ではなく見出しを当てるタスクのようで、受講生作成の要約データに対しては良いスコアは出ないのではないかと考え、自分で見た感じより良い要約をしていたStableBeluga2-70B-GPTQを要約タスク・生成タスクでも採用した。


## プロンプトの工夫

### 選択タスクのプロンプト
```
### システム:  
以下の問題の答えを考えてください。参考情報としてGoogle検索結果が与えられた場合は、答えのヒントがないか、意味をよく考えて読んでください。最初に最もふさわしい答えの選択肢番号を書いてください。最後に回答理由を解説してください。  

### ユーザー:  
[問題]:(問題)  
[選択肢]: 1. ..., 2. ..., 3. ..., 4. ..., 5. ...  

[参考: Google検索結果]:  
1. 検索ワード: "(問題) (選択肢1)"  
(検索結果)  
2. 検索ワード: "(問題) (選択肢2)"  
(検索結果)  
3. 検索ワード: "(問題) (選択肢3)"  
(検索結果)  
4. 検索ワード: "(問題) (選択肢4)"  
(検索結果)  
5. 検索ワード: "(問題) (選択肢5)"  
(検索結果)  

[答えの選択肢番号]:  

### アシスタント:  
```
Google検索して結果をプロンプトに加えるRAGを行った。計算量の削減と入力のノイズによる逆効果を防ぐため、モデルの確信度が低い場合のみRAGを行った。  
確信度は、まず検索結果を含まないプロンプトに対して次のトークンとして各選択肢番号が現れる確率によって計算し、top1の確率が一定以下、またはtop2の確率の差が一定以下の場合にRAGを行った。  
検索ワードは「問題文 選択肢」という形式で、選択肢ごとに検索した。選択肢をまとめて検索するよりも検索結果が良いように見えたのでこのようにした。  
より自然な検索ワードにするため、選択肢をLLM自身に出力させることも試したが、あまり自然な検索ワードは出力してくれなかった。  
「最初に最もふさわしい答えの選択肢番号を書いてください。」とすることで、次のトークンとして各選択肢番号が現れやすいようにした。  
「最後に回答理由を解説してください。」とすることで、より論理的な根拠に基づいた出力をするのではと期待したが、あまり違いはないようだった。  
「### システム:」「### ユーザー:」「### アシスタント:」は、Hugging Faceに記載のあった訓練時のプロンプト形式に沿ったものである。英語だと出力も英語になってしまう場合があったため、日本語にした。


### 要約タスクのプロンプト  
```
### システム:  
以下の文章を要約してください。日本語で、文字数は{length}文字以内にしてください。初めに内容の全体像が伝わる文章にしてください。キーワードを逃さずに使ってください。  

### ユーザー:  
(問題文)  

### アシスタント:  
```  
メモリの制約上max_lengthを設定していたため、出力が途中で打ち切られてしまう場合があり、長くなりすぎないように文字数を指定した。元の文章の20%の長さ(ただし100文字以上)に指定した。  
ただし、文字数はあまり守られないようだった。文の数で指定するなども試したが、やはりあまり守られなかった。(ユーザープロンプトで指示するとよかったかもしれない?)  
「初めに内容の全体像が伝わる文章にしてください。キーワードを逃さずに使ってください。」とすることで、途中で打ち切られた場合にも全体的な内容が要約に含まれるようにした。  
なお、入力文の長さ+要約文の指定した長さがmax_lengthを超える場合は、max_lengthに収まるように入力文をカットした。入力文の初めから7割程度の位置が最も重要でない部分と仮定して、そこを中心としてカット部分を決定した。


### 生成タスクのプロンプト  
```  
### システム:  
以下の指示に従って日本語で回答してください。ステップバイステップで考えて、できるだけ詳しく丁寧に回答してください。ユーザーの指示は注意深く読み、必ず守ってください。  

### ユーザー:  
(ユーザーの指示)  
最後に必ず回答理由を解説してください。  

### アシスタント:  
```  
英語で回答する場合があったので、「日本語で回答してください」と指定した。  
簡潔な回答になりがちだったので、「ステップバイステップで考えて、できるだけ詳しく丁寧に回答してください。」とした。  
問題の指示を守らない場合があった(指定された語句を順番通りに使って作文する問題で、順番を守らない)ため、「ユーザーの指示は注意深く読み、必ず守ってください。」と加えたが、改善はしなかった。  
「最後に必ず回答理由を解説してください。」と加えることで、理由が追加されより情報の多い回答になった。システムプロンプトよりユーザープロンプトとして書いたほうが、出力に反映されやすかった。


## 学習の工夫
openorca_stxではtrlライブラリを用いてJCommonsenseQAでのfine-tuningを行い、スコアが改善した。  
StableBeluga2-70B-GPTQでは、実行時間の制約からfine-tuningは行わなかった。


## その他の工夫
GPUメモリの制約があったため、GPU数に応じて最大のmax_lengthを設定するようにした。その範囲内で入力長に応じてmax_lengthを設定することで、計算時間を節約しつつ入力の情報を失わないようにした。  
問題ごとにGPUメモリをできるだけ解放することで、メモリ使用量を削減し、max_lengthを大きくすることができた。  
開発は自前のGPUで行うことで高速化と演習環境の使用時間を節約した。  
.pyファイルに分割してコーディングすることで、コードの全体像の把握やデバッガの使用をしやすくなり、開発速度が向上した。


# difficulty
transformers, trl, peftなどの高度に抽象化されたライブラリの扱いに慣れなかったが、ネット上に公開されている記事やSlack上の受講生の情報に助けられてなんとかfine-tuningをすることができた。  
Google検索でRAGを行う際に、なかなか良質な検索結果が得られないようで、そこを改善できるともう少しスコアが上がる余地があると感じた。  
GPUメモリの制約があり、制約の範囲内でできるだけ情報を失わず入出力する調整に苦労した。実行速度がある程度かかるので、開発と実行のサイクルがなかなか高速にできず、もどかしさを感じた。  
自分で手を動かしてみて、計算リソースの大事さを体感した。  
リーダーボードのデータと優秀者判定のデータが別なので、単純にリーダーボードのスコアを最大化すれば良いというわけでもない状況だったため、評価基準が難しかった。


# 感想
Slackで他の受講生と議論しながら進められたことにより、一体感が生まれ楽しかった。1人ではやらないレベルのことに挑戦できたと思う。  
このような貴重な機会を設けていただき、誠にありがとうございました。